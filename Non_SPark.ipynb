{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path =r'F:\\Study\\NU\\Data Mining\\Project\\Data' # use your path\n",
    "allFiles = glob.glob(os.path.join(path, \"*.txt\"))\n",
    "df = pd.concat((pd.read_csv(f, delimiter=\"\\t\", header=None) for f in allFiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(index=str, columns={0: \"id\", 1: \"label\", 2:\"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train,df_test,train_labels,test_labels = train_test_split(df[\"text\"],                   \n",
    "                                                 df['label'], test_size=0.20,\n",
    "                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28745\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer().fit(df_train)\n",
    "tweet_train_vectorized = vectorizer.transform( df_train)\n",
    "tweet_test_vectorized = vectorizer.transform( df_test)\n",
    "print (len(vectorizer.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.2312246806%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.48      0.45      0.46       498\n",
      "    neutral       0.62      0.63      0.63      1361\n",
      "   positive       0.67      0.68      0.67      1350\n",
      "\n",
      "avg / total       0.62      0.62      0.62      3209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfr = svm.SVC(kernel='linear', C=1)\n",
    "clfr.fit(tweet_train_vectorized,train_labels)\n",
    "predicted = clfr.predict(tweet_test_vectorized)\n",
    "acc = metrics.accuracy_score(test_labels,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (metrics.classification_report(test_labels,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.6986600187%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.47      0.45      0.46       498\n",
      "    neutral       0.63      0.63      0.63      1361\n",
      "   positive       0.68      0.69      0.68      1350\n",
      "\n",
      "avg / total       0.63      0.63      0.63      3209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(tweet_train_vectorized,train_labels)\n",
    "predicted = clf.predict(tweet_test_vectorized)\n",
    "acc = metrics.accuracy_score(test_labels,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (metrics.classification_report(test_labels,predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = open(\"F:\\\\Study\\\\NU\\\\Data Mining\\\\Project\\\\Resources\\\\stopwords.txt\", \"r\")\n",
    "lines = text_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(tweet):\n",
    "    return ' '.join(list(string for string in tweet.split(\" \") if (string not in lines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am trying to count negatvie and postive word apps within each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['p_count'] = 0\n",
    "df['n_count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"F:\\\\Study\\\\NU\\\\Data Mining\\\\Project\\\\Resources\\\\opinion-lexicon-English-Bing_liu\\\\positive-words.txt\", \"r\")\n",
    "positive_words = text_file.read().split('\\n')\n",
    "\n",
    "text_file = open(\"F:\\\\Study\\\\NU\\\\Data Mining\\\\Project\\\\Resources\\\\opinion-lexicon-English-Bing_liu\\\\negative-words.txt\", \"r\")\n",
    "negative_words = text_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_counting(tweet):\n",
    "    positive_counter = tweet.p_count\n",
    "    for string in tweet.text.split(\" \"):\n",
    "        if string in positive_words:\n",
    "            positive_counter +=1\n",
    "    return positive_counter\n",
    "\n",
    "def n_counting(tweet):\n",
    "    negative_counter = tweet.n_count\n",
    "    for string in tweet.text.split(\" \"):\n",
    "        if string in negative_words:\n",
    "            negative_counter +=1\n",
    "    return negative_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['p_count'] = df.apply(p_counting, axis=1)\n",
    "df['n_count'] = df.apply(n_counting, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
